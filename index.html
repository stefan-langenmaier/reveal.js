<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Docker composability and Gentoo instrumenting</title>
		
		<meta name="description" content="Docker's issues with composing a container and how Gentoo (or a good package manager in general) can help">
		<meta name="author" content="Stefan Langenmaier">

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h1>Docker</h1>
					<h2>und seine Build-Probleme</h2>
					<h3>und wie ein guter Paketmanager sie löst</h3>
					<p>
						<small><a href="https://github.com/stefan-langenmaier">Stefan Langenmaier</a></small>
					</p>
					
					<aside class="notes">
						Herzlich Willkommen, zum Vortrag ...
						
						Es werden hier nicht alle Buildrobleme abgehandelt, auch wenn ich versuche darauf ein paar Verweise zu setzen,
						
						sondern wir werden auf ein bestimmtes Problem näher eingehen.
						
						Der Vortrag besteht aus zwei Teilen, im ersten möchte ich dieses Problem etwas näher illustrieren
						
						Ich werde nochmal schnell über Docker und die aktuelle Container-Landschaft schauen,
						
						ich denke aber als Vorwissen ist es ideal wenn man schon mal selbst zumindest einmal docker build ausgeführt hat und das dahinterliegende Dockerfile angeschaut hat
						
						und im zweiten Teil einen Lösungsansatz mit Gentoo vorstellen.
						
						Der zweite Teil während wir auf die Installation bei Gentoo warten ist meistens der beste Punkt um Fragen zu stellen. :)
						
						
					</aside>
				</section>

				<section>
					<h2>Was ist Docker?</h2>
					<p>
						Gute Frage!
					</p>
					
					<aside class="notes">
						Ich hab diesen Vortrag schon mal vor gut vier Jahren gehalten. Da war Docker und der Container-Ansatz etwas neuer.
						<ul>
							<li>Eine Firma, von der man heute allerdings nicht mehr so viel hört. Heute eher Kubernetes/Openshift.</li>
							<li>Ein Kommandozeilenwerkzeug und Service(erstellen, starten, deployen, löschen) zum Verwalten von Container und den dazugehörigen Images auf verschiednene Platformen (linux, mac, win) und mittlerweile Architekturen.</li>
							<li>Ein Host für Images (eine Art Appstore,)</li>
							<li>Ein Bibliothek und Interface für cgroups im Linux Kernel</li>
						</ul>
						
						Docker ist jede Menge verschiedene Sachen, darum gibt es inzwischen auch jeden Menge Konkurrenz und Standardisierungen und Philosophien
						podman sehr populär im Moment
						rkt
						lxc/lxd
					</aside>
				</section>

				<section>
					<h2>Virtualisation vs Containerisation</h2>
					<p>
						Was ist der Unterschied?
					</p>
					
					<aside class="notes">
						Nur als recap
						<ul>
							<li>Full virtualised systems: jedes System hat seinen eigenen Kernel laufen. Moderne Hardware hat Support, um das mit minimalen Performan-Overhead laufen zu lassen. Ressourcen müssen dediziert zugewiesen werden.</li>
							<li>Paravirtualised systems: jedes System hat seinen eigenen Kernel laufen, aber der Kernel weiss das er virtualisiert wird.</li>
							<li>Containerized systems: alle System laufen auf dem selben Kernel. Dieser eine Kernel hat die globale Kontrolle über alle Resourcen, macht dieses aber nur eingeschränkt sichtbar für die einzelnen Systeme. Start solcher System ist extrem schnell.</li>
						</ul>
						
						<p>
							Die Performance und vor allem Ressourcenausnutzung ist dadurch besser.
							Container versprechen "create once - deploy everywhere",
							Da die Kernelschnittstelle in der Praxis tatsächlich sehr stabil kann das Versprechen meistens gehalten werden. Das schliesst allerdings keine Bugs mit ein. In diesem Fall kann z.B. ein seperater Kernel diese Versprechen vielleicht besser halten.
						</p>
					</aside>
				</section>

				<section>
					<h2>Containerization Unterschiede/Alternativen</h2>
					
					<ul>
						<li>uml</li>
						<li>OpenVZ</li>
						<li>Linux VServer</li>
					</ul>
					
					<ul>
						<li>docker</li>
						<li>podman</li>
						<li>lxc/lxd</li>
						<li>lmctfy</li>
						<li>rkt</li>
						<li>systemd-nsspawn</li>
						<li>flatpak/snap</li>
					</ul>
						
					<ul>
						<li>jails</li>
						<li>zones</li>
					</ul>
					
					<aside class="notes">
						Das ist die kleine Geschichte der Container.  
						<ul>
							<li>uml</li>
							<li>OpenVZ</li>
							<li>Linux VServer</li>
						</ul>
						Diese Lösungen gab es bereits vor den cgroups allerdings haben sie nie die Aufnahme in der Kernel geschafft oder waren proprietär.
					
						<ul>
							<li>docker</li>
							<li>podman</li>
							<li>lxc/lxd</li>
							<li>lmctfy</li>
							<li>rkt</li>
							<li>systemd-nsspawn</li>
							<li>flatpak/snap</li>
						</ul>
						Die aktuellen Optionen auf dem "Markt". Wichtig alle basieren auf cgroups. Unterschied ist die Kitchensink und wie z.B. die Daten herum ausgetauscht werden. (Images) Das ist der Punkt auf den wir eingehen werden.
						
						<ul>
							<li>jails</li>
							<li>zones</li>
						</ul>
						Auf anderen Kernels gibt es anderen Lösungen (BSD und Solaris).
						
					</aside>
				</section>

				<section>
					<h2>Bekannte Probleme von Docker</h2>
					<p>
						Ich will nicht auf <a href="#/references">alles</a> eingehen.
						
						<a href="https://github.com/moby/moby/blob/master/ROADMAP.md#12-image-builder">Aktuelles</a>
					</p>
					
					<aside class="notes">
						Links sind am Ende und Ende gibt es auch einen Link auf die Folien.
						
						Man kann verschiedene Meinungen haben, aber das Container vorerst ein Mittel der Wahl bleiben werden ist sicher.
						
						Der Vortrag richtet sich an Leute die schon docker build verwendet haben und und sich dann gedacht haben da muss ich mehr machen als nur ein COPY einer einzelnen Datei und dann läuft das.
					</aside>
				</section>

				<section>
					<h2>Das spezifische Problem</h2>
					
					<ul>
						<li>Experimentieren mit Containern/Images</li>
						<li>Erstellung eines Produktivsystems</li>
					</ul>

					<aside class="notes">
						Ich möchte über zwei Dinge sprechen
						
						Wie kann man mit einem Container experimentieren, d.h. entwickeln und testen. Dazu müssen Änderungen an den verschiedensten Stellen einfach möglich sein.
						
						Der zweite Punkt ist die Erstellung eines minimalen Containers für die Produktivumgebung. Dieser Punkt ist wichtig nicht nur aus Performance oder ästethischen Gründen.
						
						Ein Image das schnell und minimal erstellt werden kann ist ein sicheres Image.
						Wenn es schnell erstellt werden kann ist es einfach aktuell zu halten.
						Wenn es minimalen Code enthält kann nur dieser ausgenutzt werden.
						
						Daher sind diese beiden Punkte auch wenn sie unterschiedlich erscheinen miteinander verbunden.
						
						Schauen wir uns einfach an wie bekannte Projekte das machen, oder?
					</aside>
				</section>

				<section>
					<h2>Nicht betrachtet werden</h2>

					<ul>
						<li>yocto</li>
						<li>buildroot</li>
						<li>ostree</li>
					</ul>

					<aside class="notes">
						spezielle Werkzeuge für den embedded Bereich
					</aside>
				</section>
				
				<section>
					<h2>Beispiel (Phusion Passenger)</h2>
					<pre><code data-trim>
FROM phusion/baseimage:0.11
MAINTAINER Phusion &lt;info@phusion.nl&gt;

ADD . /pd_build
RUN /pd_build/install.sh
CMD ["/sbin/my_init"]
EXPOSE 80 443
					</code></pre>
					
					<a href="https://github.com/phusion/passenger-docker/blob/master/image/Dockerfile">Quelle</a>
					
					<aside class="notes">
						Das Dockerfile bildet ab wie ein Image gebaut werden soll.
						
						Das erste Beispiel ist von Phusion, die Firma hinter passenger, einem Anwendungsserver für hauptsächlich Rails-Webanwendung.
						
						Auf den ersten Blick ist das Dockerfile erstmal ziemlich übersichtlich und ich denke die Phusion Leute stimmen mit mir in einigen Punkten überein wie Images gebaut werden sollen.
						
						Aber auf den zweiten Blick?
						
						phusion/baseimage ist quasi zu unserer Distribution geworden. Es ist allerdings nicht sofort klar was das genau ist. Was ist die Philosophie von Phusion das aktuell zu halten?
						
						danach wird ein Ordner in das Image kopiert und dann ein Bash-Script ausgeführt. Da bin ich neutral dazu wir sehen später schlimmeres. Der kopierte Ordner wird auf jeden Fall in der Historie der Images bleiben.
						
						Das Bash-Skript nimmt das eigentliche Setup des Images vor. 
						
						CMD wird verwendet um das Standardkommando beim Start des Container anzugeben. Kann später überschrieben werden.
						Hier wird ein Init-System angegeben. Das entspricht nicht ganz der Docker-Philosophie, aber ebenso möglich. Nur Schade das es ausschaut als wäre hier ein custom System angegeben.
						
						Und wie aus systemd flamewars weiss reagieren manche Leute darauf sehr empfindlich. Schade also das hier ein weiteres System nötig ist obwohl es schon mehrere gibt. Aber darauf kommen wir auch noch zu sprechen.
						
						Die nächste Zeile legt die offenen Ports des Containers zur Laufzeit fest.
					</aside>
				</section>
				
				<section>
					<h2>Beispiel (Redmine)</h2>
					
					<a href="https://github.com/docker-library/redmine/blob/4064a505db909322bda24823c200f4c97985d638/4.0/Dockerfile">Redmine 4.0 Dockerfile</a>
					
					<pre><code data-trim>
FROM ruby:2.6-slim-buster
					</code></pre>
					
					<p>
						<a href="https://hub.docker.com/_/ruby">Ruby-Image-Tags</a>
					</p>
					<p>
						Wieso gibt es fünf verschiedene Varianten von ruby:2.6? Was versteckt sich dahinter?
					</p>
					<aside class="notes">
						Gibt bestimmt einen guten Grund aber bleibt weiterhin die Frage woher man weiss welchen man nehmen soll.
						
						Normal, slim oder das noch "slimmere" alpine?
					</aside>
				</section>
				
				<section>
					<h2>Beispiel (Redmine)</h2>
					
					<a href="https://github.com/docker-library/redmine/blob/4064a505db909322bda24823c200f4c97985d638/4.0/Dockerfile">Redmine 4.0 Dockerfile</a>
					
					<pre><code data-trim>
RUN set -eux; \
	savedAptMark="$(apt-mark showmanual)"; \
	apt-get update; \
	apt-get install -y --no-install-recommends \
		dirmngr \
		gnupg \
	; \
	rm -rf /var/lib/apt/lists/*; \
	\
	dpkgArch="$(dpkg --print-architecture | awk -F- '{ print $NF }')"; \
	\
# grab gosu for easy step-down from root
# https://github.com/tianon/gosu/releases
	export GOSU_VERSION='1.11'; \
	wget -O /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch"; \
	wget -O /usr/local/bin/gosu.asc "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch.asc"; \
	export GNUPGHOME="$(mktemp -d)"; \
	gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \
	gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu; \
	gpgconf --kill all; \
	rm -r "$GNUPGHOME" /usr/local/bin/gosu.asc; \
	chmod +x /usr/local/bin/gosu; \
	gosu nobody true; \
	\
# grab tini for signal processing and zombie killing
# https://github.com/krallin/tini/releases
	export TINI_VERSION='0.18.0'; \
	wget -O /usr/local/bin/tini "https://github.com/krallin/tini/releases/download/v$TINI_VERSION/tini-$dpkgArch"; \
	wget -O /usr/local/bin/tini.asc "https://github.com/krallin/tini/releases/download/v$TINI_VERSION/tini-$dpkgArch.asc"; \
	export GNUPGHOME="$(mktemp -d)"; \
	gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys 6380DC428747F6C393FEACA59A84159D7001A4E5; \
	gpg --batch --verify /usr/local/bin/tini.asc /usr/local/bin/tini; \
	gpgconf --kill all; \
	rm -r "$GNUPGHOME" /usr/local/bin/tini.asc; \
	chmod +x /usr/local/bin/tini; \
	tini -h; \
	\
# reset apt-mark's "manual" list so that "purge --auto-remove" will remove all build dependencies
	apt-mark auto '.*' > /dev/null; \
	[ -z "$savedAptMark" ] || apt-mark manual $savedAptMark; \
	apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false
					</code></pre>
					
					Ziemlich lange Zeile
					
					<aside class="notes">
						Hier wird versucht zu vermeiden eine Skript-Ordner zu kopieren. Wahrscheinlich auf Kosten der Lesbarkeit. Ich bin mir fast sicher das man das in einem Shell-Skript besser hinbekommt.
						
						Damit hat man auf jeden Fall schwierige Debug Problem, wenn man ein Zeichen vergisst und eine Zeile erneut auszuführen kann lange dauern. Schnelle Iterationszyklen werden verhindert.
					</aside>
				</section>
				
				<section>
					<h2>Docker build capabilities</h2>
					
					Nicht verfügbar
					
					<aside class="notes">
						ncurses cannot be built because this uses ptrace syscall,
						this is syscall which is not allowed by default
						you can use add-cap, but not during build only during run
					</aside>
				</section>
				
				<section>
					<h2>Umgebungsvariablen</h2>
					
					Nicht verfügbar
					
					<aside class="notes">
					</aside>
				</section>
				
				<section>
					<h2>Mounts</h2>
					
					Nicht verfügbar
					
					<aside class="notes">
						man kann keine Verzeichnisse mounten die nur während des Builds vorhanden sein sollen
					</aside>
				</section>
				
				<section>
					<h2>Docker multistage build</h2>
					
					Langsam
					
					<aside class="notes">
						copy data around from one image to the next
						to reduce the end image size
						time consuming
					</aside>
				</section>
				
				<section>
					<h2>Rant Resumé</h2>
					
					Bekannte Limitierungen - könnten technisch gelöst werden.
					
					<aside class="notes">
						Der letzte Punkt wahrscheinlich nicht direkt, denn der build Prozess möchte reproducible builds, auch wenn die Ergebnisse nicht reproducible im Sinne von Debian oder NixOS sind.
						
						I don't want to bash this Docker build here/actually I wanted to
						what I want to say is that assembling a Linux system is hard
						that's why there is a plethora of different package managers out there
						They have been in development in a long time
						There are distributions with packagers out there with intimate knowledge about their users and their packages
						They feed these package mangers with information
						
						You don't want to throw this knowledge away but use it (and built it yourself see the Dockerfile dance)
						
						insert xkcd
					</aside>
				</section>

				
				<section>
					<h2>Beispielproblem (Nextcloud)</h2>
					<table>
						<thead>
							<tr>
								<td></td>
								<td>Webserver-Interface</td>
								<td>PHP</td>
								<td>DB</td>
								<td>Nextcloud</td>
								<td>Sum</td>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Kombinationen</td>
								<td>2</td>
								<td>3</td>
								<td>3</td>
								<td>3</td>
								<td></td>
							</tr>
							<tr>
								<td style="white-space: nowrap;">Docker (*)</td>
								<td>2</td>
								<td>6</td>
								<td>18</td>
								<td>54</td>
								<td>80</td>
							</tr>
							<tr>
								<td style="white-space: nowrap;">Komposition (+)</td>
								<td>2</td>
								<td>5</td>
								<td>8</td>
								<td>11</td>
								<td>11</td>
							</tr>
						</tbody>
					</table>
					<aside class="notes">
						Wir wollen hier nextcloud installieren. Dabei müssen wir einige Komponenten auswählen.
						
						Die Anzahl der möglichen Kombination der Komponenten ist in beiden Fällen die gleiche, aber die Anazahl der nötigen Zwischenschritte steigt rapide an (linear vs exponentiell)
						
						Jede weitere Dimension mit der wir experimentieren wollen macht das Problem noch schwerwiegender. Man hat mit dem Curse of Dimensions zu tun.
						
						Das ist natürlich ein reines Spiel mit Zahlen. Es gibt im produktiven Einsatz wahrscheinlich nicht alle möglichen Kombinationen der PHP-Extensions. Wir werden auch nicht alle Kombinationen durchgenen. Diese muss man aber während der Entwicklung schon irgendwie als Möglichkeit haben.
						
						Das Verhalten wenn weitere Dimensionen wie  accelerators APCu oder Caches Redis/Memcache hinzukommen wird nur noch schlimmer.
						
						Das Problem mag einfach erscheinen aber es ist das selbe das hinter der Dependency Hell steckt oder anderen kombinatorischen Explosionen bei der Versionierung von Artefakten
						
						https://worklifenotes.com/2020/03/04/microservices-combinatorial-explosion-of-versions/
					</aside>
				</section>
				
				<section>
					<h2>Let's visualize it (stacked)</h2>
					<div id="stackednetwork" style="height: 50vh; width: 100%;"></div>
					
					<aside class="notes">
						Um das nochmal zu veranschaulichen habe ich das grafisch dargestellt. Man will zu einem bestimmten Blatt unten kommen. Das ist eine gewünschte Konfiguration. Und beim Testen will man zwischen den Blättern springen können.
						
						Damit das schnell geht möchte man den Unterbau möglicht gering halten.
						
						Eine Entscheidung auf einer niedrigen Ebene hat Einfluss auf alles darüber.
					</aside>
				</section>
				
				<section>
					<h2>Let's visualize it (composed)</h2>
					<div id="composednetwork" style="height: 50vh; width: 100%;"></div>
					
					<aside class="notes">
						Pakete können mit verschieden anderen Paketen zusammenarbeiten, daher können sie wiederverwendet werden.
					</aside>
				</section>
				
				
				<section>
					<h2>Dieses Problem kann man ignorieren, wenn man</h2>
					<ul>
						<li>Fan von Monokulturen ist</li>
						<li>auf Vendor Lock-in steht</li>
						
					</ul>
					<aside class="notes">
						Das Phänomen wird ersichtlich wenn man bemerkt das es zu aufwenig ist von einem basimage auf ein anderes zu wechseln.
					</aside>
				</section>

				<section>
					<h2>Die Lösung</h2>
					<p>gute Paketmanager</p>
					<ul>
						<li>Stabilität</li>
						<li>Support</li>
						<li>Best Practices</li>
						<li>Dokumentation</li>
					</ul>
					<aside class="notes">
						Paketmanager gibt es schon eine ganze Weile, sie sind sehr stabil und haben Dokumentation.
						Es gibt eine etablierte Dokumentation mit dem Upstream.
						Wird von Leuten erstellt die das Gesamtsystem im Auge haben mit Best-Practices.

						Jedes Mal wenn man eine Anwendung ohne Paketmanager aufsetzt sagt man quasi man kennt die Anwendung besser als die Entwickler der Distribution. Das mag bei einer selbst-entwickelten Anwendung der fall sein, aber trifft das auch auf alle Abhängigkeiten zu?
					</aside>
				</section>
				
				<section>
					<h2>Rekapitulation</h2>

					<p>
					Fokus auf die Erstellung der Images (mit "normalem" Paketmanager)
					</p>

					<aside class="notes">
						Will nicht Docker, noch Container als Lösung in Frage stellen. Docker is "here to stay" bzw nicht unbedingt Docker aber die Ausführung von Anwendung in Containern.
						
						Aber ich will die Weise wie `docker build` arbeitet und insbesondere wie es schiefläuft wenn man anfangen will eigene Images zu bauen.
						
						Normale Paketmanager machen das nur schon ein paar Dekaden. Das Ziel ist es zu zeigen wie sie dabei helfen:
						* effizient Images zu bauen
						* auf eine sichere Art und Weise
						* mit einer sinnvollen Grösse (man musst die erzeugten Images ja dann doch noch austauschen)
						
						Ich mache das im nachfolgenden mit Gentoo, bin mir sehr bewusst das andere das auch können
						würde micht über einen Talk freuen der mich ich einem der Punkt one-upped.
					</aside>
				</section>
				
				<section>
					<h2>Beispiel - ein Image für Nextcloud</h2>

					<p>
						 Referenz: das offizielle <a href="https://hub.docker.com/_/nextcloud?tab=description">Image (18-apache)</a>.
					</p>

					<aside class="notes">
						Wir schauen uns zuerst das Image an.
						
						<pre>
						cd work
						docker create --name nextcloud-apache nextcloud:18-apache
						docker export nextcloud-apache | tar -xv
						baobab .
						</pre>
						
						Grossteil macht die ilbc und Nextcloud Installation aus
						
						Wir sehen aber das auch ein Init-System vorhanden ist.
					</aside>
				</section>
				
				<section>
					<h2>Setup</h2>
					<ol>
						<li>export PORTAGE_CONFIGROOT=/var/build-root/portage-configroot/</li>
						<li>export ROOT=/var/build-root/rootfs/</li>
						<li>emerge @system -av --jobs=5</li>
					</ol>
					
					<aside class="notes">
						Das Setup sollte mit eigentlich jeder Distribution möglich sein. Ich verwende aber ein paar Eigenschaften von Gentoo die mir hier sehr nützlich erscheinen.
						
						Das sind hauptsächlich zwei Umgebungsvariablen ROOT und PORTAGE_CONFIGROOT. Sie setzen ein alternative Verzeichnisse für den Paketmanager
						
						Profile in Gentoo ermöglich einige Voreinstellungen. Darunter z.B. Standardpakete die installiert werden sollen. In Containern sind nicht alle Pakete nötig die auf einer physischen Maschine laufen.
						Das Profil ist nicht in Gentoo, ich hab das auf Github, falls da jemand interessiert ist.
						
						Emerge ist der Paketmanager und @world ist die Sammlung aller Pakete für dieses System. Da der Ordner leer ist. Wird das komplette System darin erzeugte werden. `-av` frägt mich nochmal.
					</aside>
				</section>
				
				<section>
					<h2>Setup II</h2>
					<ol>
						<li>emerge nextcloud --onlydeps --jobs=5 -av</li>
						<li>emerge nginx --jobs=5 -av</li>
					</ol>
					
					<aside class="notes">
						Baobab
						Gentoo Image ist grösser, das liegt zum einen daran das wir glibc verwenden. Vorteil ist wir haben weniger Stress mit Paketen die nicht so gut getestet sind mit musl. Anscheind auch Performance ist besser in manchen Fällen, z.B. auflösen von DNS-Sachen. Aber ich will hier auch nicht in einen Flamewar.
						
						Das ist aber nicht der einzige Grund. Alpine baut manche Pakete ohne Doku und manpages und nicht alle Pakete in Gentoo machen das.
						
						In Gentoo ist das gcc Paket nicht gut aufgeteilt.
						
						Wir haben ein komplettes init-Sytem mit dabei. Vorteil das Image kann mit der Dockerphilosophie gestartet werden oder klassisch wie eine VM. Nützlich wenn man sich keinen Kopf machen will um z.B. einen Cron in seiner Anwendung mitlaufen lassen will.
						
						Alpine hat aber z.B. für alle Datenbank-Triber mit dabei. Das ist ein Vorteil unseres Images.
						
						Ich zieh meinen Hut vor den Alpine Leuten die Standard-Installation ist kleiner. Ich bin aber ein schlechter Verlierer und werf noch händisch unnötiges Zeug raus.
						
						delete documentation
						delete locales
						delete includes
						
						Damit sollte alles gezeigt sein:
						* wir können damit kleinere Images bauen (sicherer)
						* wir haben mehr Funktionalität und Flexibiltät 
						* wir können existierende Paketmanager verwenden (existierendes Wissen)
						* und sind damit nicht auf die Image-Ersteller als Mittelsmann angewiesen (keine vendor lockin)
					</aside>
				</section>
				
				<section>
					<h2>Setup III</h2>
					<ol>
						<li>unset ROOT</li>
						<li>unset PORTAGE_CONFIGROOT</li>
						echo "www-apps/nextcloud ~amd64" >> /etc/portage/package.accept_keywords
						echo "www-apps/nextcloud vhosts" >> /etc/portage/package.use/nextcloud
						emerge webapp-config -av
						<li>emerge -O nextcloud -av</li>
						mkdir -p /var/build-root/rootfs/usr/share/webapps          
						ln -sf /usr/share/webapps/nextcloud /var/build-root/rootfs/usr/share/webapps/nextcloud
						<li>webapp-config -d nextcloud -s nginx -c -I nextcloud 18.0.1</li>
					</ol>
					
					<aside class="notes">
						Baobab
						Gentoo Image ist grösser, das liegt zum einen daran das wir glibc verwenden. Vorteil ist wir haben weniger Stress mit Paketen die nicht so gut getestet sind mit musl. Anscheind auch Performance ist besser in manchen Fällen, z.B. auflösen von DNS-Sachen. Aber ich will hier auch nicht in einen Flamewar.
						
						Das ist aber nicht der einzige Grund. Alpine baut manche Pakete ohne Doku und manpages und nicht alle Pakete in Gentoo machen das.
						
						In Gentoo ist das gcc Paket nicht gut aufgeteilt.
						
						Wir haben ein komplettes init-Sytem mit dabei. Vorteil das Image kann mit der Dockerphilosophie gestartet werden oder klassisch wie eine VM. Nützlich wenn man sich keinen Kopf machen will um z.B. einen Cron in seiner Anwendung mitlaufen lassen will.
						
						Alpine hat aber z.B. für alle Datenbank-Triber mit dabei. Das ist ein Vorteil unseres Images.
						
						Ich zieh meinen Hut vor den Alpine Leuten die Standard-Installation ist kleiner. Ich bin aber ein schlechter Verlierer und werf noch händisch unnötiges Zeug raus.
						
						delete documentation
						delete locales
						delete includes
						
						Damit sollte alles gezeigt sein:
						* wir können damit kleinere Images bauen (sicherer)
						* wir haben mehr Funktionalität und Flexibiltät 
						* wir können existierende Paketmanager verwenden (existierendes Wissen)
						* und sind damit nicht auf die Image-Ersteller als Mittelsmann angewiesen (keine vendor lockin)
					</aside>
				</section>

				<section>
					<h2>Aufräumen</h2>

					<ol>
						<li>bash ./cleanup.sh</li>
					</ol>
					
					<aside class="notes">
						Wir löschen Dateien die nicht benötigt werden.

						Wir schalten noch ein paar Standarddienste die in Containern nicht gebraucht werden aus.
					</aside>
				</section>

				<section>
					<h2>Image-Erstellung</h2>

					<ol>
						<li>sudo tar -c . | sudo docker import - &lt;imagename&gt;</li>
					</ol>
					
					<aside class="notes">
						Images sind praktisch für den Austausch.
						Wenn man am Ende der Entwicklung aber eine austauschbares Images haben möchte, kann das wie hier beschrieben erstellt werden.
						
						Zu Beginn wollteich kleiner als das Alpine-Image werden, aber das habe ich nicht ganz geschafft (ca. 20% kleiner). :)
						really small but size is not the most important, it's important to understand what's in you container
					</aside>
				</section>

				<section>
					<h2>Funktion</h2>

					<ol>
						<li>docker run --rm --tmpfs /run -it --name nextcloud -p 127.0.0.1:8080:80/tcp testimage /sbin/init</li>
					</ol>
					
					<aside class="notes">
						Jetzt muss man nur noch zeigen, dass das erstellte Image funktioniert.
						
						Hier wird als Webserver noch ein Nginx-Container gestartet.
					</aside>
				</section>

				<section>
					<h2>Danke - Q/A</h2>
				</section>

				<section id="references">
					<h1>Links/References</h1>

					<ul>
						<li><a href="http://en.wikipedia.org/wiki/Operating-system-level_virtualization">Wikipedia: Operating-system-level Virtualization</a></li>
						<li><a href="https://pythonspeed.com/articles/alpine-docker-python/">Alpine-Docker &amp; Pyhton</a></li>
						<li><a href="https://github.com/docker-slim/docker-slim">Profiling for image reduction</a></li>
						<li><a href="https://jaxenter.com/anti-docker-blog-114422.html">Boycott Docker</a></li>
						<li><a href="http://thenewstack.io/coreos-calls-docker-fundamentally-flawed-releases-prototype-alternative/">coreos and rocket</a></li>
						<li><a href="https://www.packer.io/docs/builders/docker.html">packer</a></li>
						<li><a href="https://buildah.io/">buildah</a></li>
						<li><a href="http://www.vitavonni.de/blog/201503/2015031201-the-sad-state-of-sysadmin-in-the-age-of-containers.html">container rant</a></li>
						<li><a href="https://chimeracoder.github.io/docker-without-docker">Docker without Docker</a></li>
					</ul>
				</section>

			</div>
		</div>

		<script src="js/reveal.js"></script>
		<script src="js/vis-network.min.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				//controls: true,
				//progress: true,
				history: true,
				width: "100%",
				height: "100%",
				//center: true,
				
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true }
				]
			});
		</script>
		
		<script type="text/javascript">
			var levels = [ 2, 3, 3, 3 ];
			var nodeIdCounter = 0;
			function generateGraph(levels, data, level, nodeId) {
				var nodes = data['nodes'];
				var edges = data['edges'];
				for (var i = 0; i < levels[level]; i++) {
					nodes.add({
						id : nodeIdCounter,
						label : "*",
						level : level + 1
					});
					edges.add({
						from : nodeId,
						to : nodeIdCounter
					});
					nodeIdCounter++;
					if (level <= levels.length) {
						data = generateGraph(levels, data, level + 1,
								nodeIdCounter - 1);
					}
				}

				return data;
			}

			// create an array with nodes
			var nodes = new vis.DataSet([ {
				id : nodeIdCounter++,
				label : 'LDB',
				level : 0
			} ]);

			// create an array with edges
			var edges = new vis.DataSet([]);

			// create a network
			var container = document.getElementById("stackednetwork");
			var data = {
				nodes : nodes,
				edges : edges
			};
			var options = {
				layout : {
					hierarchical : {
						enabled : true,
						direction : 'UD'
					}
				}
			};
			data = generateGraph(levels, data, 0, nodeIdCounter - 1);
			var network = new vis.Network(container, data, options);
		</script>

		<script type="text/javascript">
		var levels = [ 2, 3, 3, 3 ];
		var nodeIdCounter = 0;

			function generateGraph(levels, data, level, nodeId) {
				var nodes = data['nodes'];
				var edges = data['edges'];
				for (var i = 0; i < levels[level]; i++) {
					nodes.add({
						id : nodeIdCounter,
						label : "*",
						level : level + 1
					});
					for (var k = 0; k < nodes.length; k++) {
						var n = nodes.get(k);
						if (n['level'] === level) {
							edges.add({
								from : n['id'],
								to : nodeIdCounter
							});
						}
					}
					nodeIdCounter++;

				}
				if (level <= levels.length) {
					data = generateGraph(levels, data, level + 1,
							nodeIdCounter - 1);
				}

				return data;
			}

			// create an array with nodes
			var nodes = new vis.DataSet([ {
				id : nodeIdCounter++,
				label : 'LDB',
				level : 0
			} ]);

			// create an array with edges
			var edges = new vis.DataSet([]);

			// create a network
			var container = document.getElementById("composednetwork");
			var data = {
				nodes : nodes,
				edges : edges
			};
			var options = {
				layout : {
					hierarchical : {
						enabled : true,
						direction : 'UD'
					}
				}
			};
			data = generateGraph(levels, data, 0, nodeIdCounter - 1);
			var network = new vis.Network(container, data, options);
		</script>
	</body>
</html>
